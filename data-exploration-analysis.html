<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Data Exploration and Analysis ‚Äî Understanding Your Data Deeply</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=DM+Mono:wght@400;500&display=swap');
@import url('https://fonts.googleapis.com/css2?family=Syne:wght@400;600;700;800&family=Syne+Mono&display=swap');

:root {
  --bg: #04040a;
  --accent: #7b2fff;
  --hot: #ff2d78;
  --cool: #00e5ff;
  --warm: #ffb800;
  --green: #00ff9d;
  --text: #e0e0f0;
  --muted: #4a4a6a;
  --card: #0a0a14;
  --border: rgba(255,255,255,0.07);
}

* { box-sizing: border-box; margin: 0; padding: 0; }
html { scroll-behavior: smooth; }

body {
  background: var(--bg);
  color: var(--text);
  font-family: 'Syne', sans-serif;
  overflow-x: hidden;
  line-height: 1.8;
}

body::before {
  content: '';
  position: fixed; inset: 0; z-index: 0;
  background:
    radial-gradient(ellipse 100% 60% at 50% 0%, rgba(123,47,255,0.12) 0%, transparent 60%),
    radial-gradient(ellipse 60% 40% at 0% 100%, rgba(0,229,255,0.06) 0%, transparent 60%);
  pointer-events: none;
}

.wrap { position: relative; z-index: 1; max-width: 1100px; margin: 0 auto; padding: 0 28px; }

nav {
  position: sticky; top: 0; z-index: 100;
  background: rgba(4,4,10,0.9);
  backdrop-filter: blur(24px);
  border-bottom: 1px solid var(--border);
  padding: 14px 28px;
  display: flex; align-items: center; gap: 10px; flex-wrap: wrap;
}
.nav-brand { font-family: 'Bebas Neue', sans-serif; font-size: 20px; color: var(--accent); margin-right: auto; letter-spacing: 2px; }
.nav-pill {
  font-family: 'Syne Mono', monospace; font-size: 10px; letter-spacing: 2px;
  padding: 5px 12px; border-radius: 20px; border: 1px solid rgba(123,47,255,0.4);
  color: rgba(123,47,255,0.8); text-decoration: none; transition: all 0.2s;
}
.nav-pill:hover { background: rgba(123,47,255,0.15); border-color: var(--accent); color: #fff; }

.hero { padding: 90px 0 50px; }
.hero-eyebrow {
  font-family: 'Syne Mono', monospace; font-size: 11px; letter-spacing: 4px;
  color: var(--accent); text-transform: uppercase; margin-bottom: 18px;
  display: flex; align-items: center; gap: 12px;
}
.hero-eyebrow::after { content: ''; flex: 1; height: 1px; background: rgba(123,47,255,0.3); }

.hero h1 {
  font-family: 'Bebas Neue', sans-serif;
  font-size: clamp(48px, 10vw, 100px);
  line-height: 0.92; margin-bottom: 28px;
  color: #fff;
}

.hero-desc { max-width: 750px; font-size: 16px; color: rgba(210,210,240,0.72); line-height: 1.8; margin-bottom: 40px; }

section { padding: 70px 0; border-top: 1px solid var(--border); }
.section-label { font-family: 'Syne Mono', monospace; font-size: 10px; letter-spacing: 4px; color: var(--accent); text-transform: uppercase; margin-bottom: 16px; }
.section-title { font-family: 'Bebas Neue', sans-serif; font-size: clamp(36px, 6vw, 64px); line-height: 1; margin-bottom: 40px; color: #fff; }

.concept-card {
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 16px;
  padding: 40px;
  margin-bottom: 36px;
  border-left: 4px solid var(--card-accent, var(--accent));
  transition: all 0.3s;
}

.concept-card:hover {
  border-color: var(--card-accent, var(--accent));
  background: linear-gradient(135deg, rgba(255,255,255,0.02) 0%, transparent 100%);
  transform: translateY(-2px);
}

.concept-title {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 28px;
  color: var(--card-accent, var(--accent));
  margin-bottom: 20px;
  letter-spacing: 1px;
}

.concept-body {
  font-size: 15px;
  color: rgba(210,210,240,0.88);
  line-height: 1.9;
  margin-bottom: 28px;
}

.concept-body p {
  margin-bottom: 18px;
}

.concept-body strong {
  color: #fff;
}

.code-block {
  background: rgba(0,0,0,0.5);
  border: 1px solid rgba(0,229,255,0.2);
  border-radius: 12px;
  padding: 24px;
  margin: 28px 0;
  font-family: 'DM Mono', monospace;
  font-size: 13px;
  color: #fff;
  overflow-x: auto;
  line-height: 1.6;
}

.code-comment { color: #5c7a8a; }
.code-keyword { color: var(--accent); }
.code-string { color: var(--green); }
.code-number { color: var(--warm); }
.code-function { color: var(--cool); }

.teaching-box {
  background: rgba(123,47,255,0.1);
  border-left: 4px solid var(--accent);
  padding: 24px;
  border-radius: 10px;
  margin: 28px 0;
  font-size: 15px;
  color: rgba(210,210,240,0.9);
  line-height: 1.8;
}

.teaching-box strong {
  color: #fff;
}

.comparison-box {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: 20px;
  margin: 28px 0;
}

.comparison-card {
  background: rgba(0,0,0,0.3);
  border: 1px solid rgba(255,255,255,0.08);
  border-radius: 12px;
  padding: 24px;
  border-left: 3px solid var(--comp-color, var(--accent));
}

.comp-title {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 16px;
  color: var(--comp-color, var(--accent));
  margin-bottom: 14px;
  letter-spacing: 1px;
}

.comp-content {
  font-size: 13px;
  color: rgba(200,200,220,0.85);
  line-height: 1.8;
}

.impact-box {
  background: linear-gradient(135deg, rgba(123,47,255,0.15) 0%, rgba(0,229,255,0.08) 100%);
  border: 1px solid rgba(123,47,255,0.3);
  border-radius: 14px;
  padding: 32px;
  margin-top: 32px;
}

.impact-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
  gap: 28px;
}

.impact-item {
  padding: 24px;
  background: rgba(0,0,0,0.2);
  border-radius: 10px;
  border-left: 4px solid var(--impact-color, var(--accent));
}

.impact-item-title {
  font-family: 'Syne Mono', monospace;
  font-size: 12px;
  letter-spacing: 2px;
  color: var(--impact-color, var(--accent));
  text-transform: uppercase;
  margin-bottom: 14px;
  font-weight: 600;
}

.impact-item-content {
  font-size: 13px;
  color: rgba(200,200,220,0.88);
  line-height: 1.8;
}

.timeline {
  position: relative;
  padding: 40px 0;
}

.timeline-item {
  padding: 28px;
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 10px;
  margin-bottom: 24px;
  margin-left: 40px;
  position: relative;
}

.timeline-item::before {
  content: '';
  position: absolute;
  left: -32px;
  top: 32px;
  width: 16px;
  height: 16px;
  background: var(--accent);
  border-radius: 50%;
  border: 3px solid var(--bg);
}

.timeline-item::after {
  content: '';
  position: absolute;
  left: -24px;
  top: 48px;
  width: 2px;
  height: 44px;
  background: rgba(123,47,255,0.3);
}

.timeline-item:last-child::after {
  display: none;
}

.timeline-title {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 18px;
  color: var(--cool);
  margin-bottom: 10px;
  letter-spacing: 1px;
}

.timeline-desc {
  font-size: 14px;
  color: rgba(200,200,220,0.85);
  line-height: 1.8;
}

.insight-box {
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 12px;
  padding: 32px;
  margin: 28px 0;
  border-left: 4px solid var(--insight-color, var(--accent));
}

.insight-title {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 20px;
  color: var(--insight-color, var(--accent));
  margin-bottom: 16px;
  letter-spacing: 1px;
}

.insight-content {
  font-size: 15px;
  color: rgba(210,210,240,0.88);
  line-height: 1.8;
}

footer {
  padding: 60px 0 40px;
  border-top: 1px solid var(--border);
  text-align: center;
}

.footer-text {
  font-family: 'Syne Mono', monospace;
  font-size: 11px;
  letter-spacing: 2px;
  color: var(--muted);
  text-transform: uppercase;
}

@media (max-width: 768px) {
  .hero { padding: 60px 0 40px; }
  section { padding: 50px 0; }
  .impact-grid { grid-template-columns: 1fr; }
  .comparison-box { grid-template-columns: 1fr; }
}
</style>
</head>
<body>

<nav>
  <div class="nav-brand">DATA EXPLORATION</div>
  <a href="#statistics" class="nav-pill">Statistics</a>
  <a href="#visualization" class="nav-pill">Visualization</a>
  <a href="#relationships" class="nav-pill">Relationships</a>
  <a href="#workflow" class="nav-pill">Workflow</a>
</nav>

<div class="wrap">

  <section class="hero">
    <div class="hero-eyebrow">Seeing Patterns in Numbers</div>
    <h1>Data Exploration and Analysis</h1>
    <p class="hero-desc">Before building any machine learning model, before engineering features, before even cleaning data properly, you must understand what you're working with. Data exploration is how you develop that understanding. It transforms raw numbers into insights about patterns, distributions, relationships, and anomalies. A dataset is not just abstract data‚Äîit represents a story about the real world, and exploration is how you read that story. You discover which values appear frequently and which rarely. You find hidden relationships between variables. You detect errors and inconsistencies. You identify questions your data can answer and questions it cannot. Professional data scientists spend substantial time exploring data because this foundational understanding drives every downstream decision. The insights you gain during exploration inform which algorithms to try, which preprocessing steps are needed, which features matter most, and even whether a problem is solvable with the data available. This section teaches you to explore data systematically using both numerical statistics and visual analysis, revealing patterns that lead to genuine understanding.</p>
  </section>

  <section id="statistics">
    <div class="section-label">Quantifying Data Characteristics</div>
    <h2 class="section-title">Descriptive Statistics and Summary Measures</h2>

    <div class="concept-card" style="--card-accent: var(--cool);">
      <div class="concept-title">üìä Understanding Distributions Through Numbers</div>
      <div class="concept-body">
        <p>Descriptive statistics are the numerical language for describing data. Rather than listing every single value in your dataset, statistics summarize the essential characteristics in a few numbers that tell a coherent story. The mean tells you the center of the data. The standard deviation tells you how spread out the values are. The median tells you what a typical value looks like when you account for extreme values. Together, these numbers paint a picture of what your data is like.</p>

        <p>The mean is the arithmetic average‚Äîyou sum all values and divide by how many there are. The mean is intuitive and easy to understand, but it has an important weakness: extreme values pull it in their direction. In a dataset of salaries where most people earn 50,000 dollars but one person earns 5,000,000, the mean might be misleading about what a typical salary is. This is why the median‚Äîthe middle value when data is sorted‚Äîis equally important. The median is robust to extreme values. It tells you the salary that half the people earn more than and half earn less than, regardless of how extreme the highest and lowest salaries are.</p>

        <p>The standard deviation measures how spread out the values are around the mean. When standard deviation is small, values cluster tightly around the mean. When standard deviation is large, values are scattered widely. Understanding this spread is crucial because algorithms make different assumptions about spread. Some algorithms perform better on data with large spread; others on data with small spread. Standardization (subtracting the mean and dividing by standard deviation) is one of the most common preprocessing steps, and you can only do it properly if you understand what these numbers mean.</p>

        <p>Percentiles divide your data into 100 equal parts. The 25th percentile (first quartile) is the value where 25 percent of your data falls below and 75 percent above. The 50th percentile is the median. The 75th percentile is where 75 percent falls below and 25 percent above. The interquartile range‚Äîthe difference between the 75th and 25th percentiles‚Äîtells you where the middle half of your data falls. These quartiles are how box plots, one of the most useful visualizations, are constructed.</p>
      </div>

      <div class="teaching-box">
        Think of descriptive statistics as a translator between raw numbers and human understanding. The mean is like asking "what's the typical value?" The median is like asking "what's the middle value?" The standard deviation is like asking "how much variation is there?" Percentiles are like asking "what value has this proportion of data below it?" Together, these questions create a complete picture of what your data looks like numerically.
      </div>

      <div class="code-block">
<span class="code-comment"># Computing descriptive statistics with Pandas</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Load data</span>
df = pd.read_csv(<span class="code-string">'housing_prices.csv'</span>)

<span class="code-comment"># Describe automatically computes key statistics</span>
<span class="code-function">print</span>(df.describe())  <span class="code-comment"># Returns count, mean, std, min, 25%, 50%, 75%, max</span>

<span class="code-comment"># Access individual statistics</span>
mean_price = df[<span class="code-string">'price'</span>].mean()
median_price = df[<span class="code-string">'price'</span>].median()
std_price = df[<span class="code-string">'price'</span>].std()
variance_price = df[<span class="code-string">'price'</span>].var()  <span class="code-comment"># Variance is std squared</span>

<span class="code-comment"># Get percentiles manually</span>
q25 = df[<span class="code-string">'price'</span>].quantile(<span class="code-number">0.25</span>)  <span class="code-comment"># 25th percentile</span>
q50 = df[<span class="code-string">'price'</span>].quantile(<span class="code-number">0.50</span>)  <span class="code-comment"># 50th percentile (median)</span>
q75 = df[<span class="code-string">'price'</span>].quantile(<span class="code-number">0.75</span>)  <span class="code-comment"># 75th percentile</span>
iqr = q75 - q25  <span class="code-comment"># Interquartile range</span>

<span class="code-comment"># Compare mean and median to understand skewness</span>
<span class="code-function">print</span>(<span class="code-string">f"Mean: {mean_price:.2f}, Median: {median_price:.2f}"</span>)
<span class="code-comment"># If mean > median: data is right-skewed (long tail to right)</span>
<span class="code-comment"># If mean < median: data is left-skewed (long tail to left)</span>
<span class="code-comment"># If mean ‚âà median: data is approximately symmetric</span>

<span class="code-comment"># Compute mode (most frequent value)</span>
mode_price = df[<span class="code-string">'price'</span>].mode()[<span class="code-number">0</span>]  <span class="code-comment"># Most common price</span>

<span class="code-comment"># Check for skewness explicitly</span>
skewness = df[<span class="code-string">'price'</span>].skew()
<span class="code-comment"># Skewness = 0: symmetric distribution</span>
<span class="code-comment"># Skewness > 0: right-skewed (tail to right)</span>
<span class="code-comment"># Skewness < 0: left-skewed (tail to left)</span>

<span class="code-comment"># Compute statistics grouped by category</span>
by_neighborhood = df.groupby(<span class="code-string">'neighborhood'</span>)[<span class="code-string">'price'</span>].agg([
    <span class="code-string">'count'</span>, <span class="code-string">'mean'</span>, <span class="code-string">'median'</span>, <span class="code-string">'std'</span>, <span class="code-string">'min'</span>, <span class="code-string">'max'</span>
])
<span class="code-comment"># This shows statistics broken down by neighborhood</span>
      </code-block>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--cool);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">Understanding statistics is the first step of any data exploration. Before you visualize data, before you preprocess it, you compute these numbers to understand what you're working with. Machine learning frameworks use these statistics for normalization and preprocessing. Reporting results requires understanding statistics to communicate findings meaningfully.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--hot);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Statistics compress information into interpretable numbers. They reveal whether data is symmetric or skewed, concentrated or spread out, typical or extreme. This understanding informs preprocessing decisions, feature engineering choices, and algorithm selection. You cannot make good decisions without understanding these characteristics.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--green);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">First thing after loading data. Computing statistics should be automatic, reflexive. These numbers guide your entire exploration. They highlight which variables need transformation. They reveal which groups have different characteristics. Statistics are the quantitative foundation that visualizations build upon.</div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <section id="visualization">
    <div class="section-label">Seeing Data Patterns</div>
    <h2 class="section-title">Visualization: Histograms, Box Plots, and Distributions</h2>

    <div class="concept-card" style="--card-accent: var(--green);">
      <div class="concept-title">üìà Histograms: The Shape of Distributions</div>
      <div class="concept-body">
        <p>A histogram is one of the most important tools for understanding your data. It shows how values are distributed across a range. The x-axis shows the range of possible values divided into bins (intervals). The y-axis shows how many data points fall into each bin. By looking at the shape, you immediately understand the distribution. Is it bell-shaped (normal distribution)? Is it skewed with a long tail? Are there multiple peaks suggesting the presence of distinct groups?</p>

        <p>Histograms reveal patterns that raw statistics cannot. Two datasets with the same mean and standard deviation can have completely different histograms‚Äîone might be bell-shaped while the other is uniform or bimodal. This is why Anscombe's Quartet, a famous example with four datasets that have identical statistics but different histograms, is used to teach the importance of visualization. You literally cannot make good decisions about preprocessing or modeling without seeing the actual distribution shape.</p>

        <p>The bin width you choose affects what patterns you see. Too many narrow bins and the histogram becomes jagged and hard to interpret. Too few wide bins and you lose detail about the true distribution. Choosing appropriate bin width is a small but important skill that comes with practice. Most plotting libraries choose reasonable defaults, but understanding how bins work helps you experiment and find what reveals the patterns in your specific data.</p>
      </div>

      <div class="code-block">
<span class="code-comment"># Creating histograms to understand distributions</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

df = pd.read_csv(<span class="code-string">'data.csv'</span>)

<span class="code-comment"># Basic histogram with default settings</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">6</span>))
plt.hist(df[<span class="code-string">'price'</span>], bins=<span class="code-number">30</span>, edgecolor=<span class="code-string">'black'</span>, alpha=<span class="code-number">0.7</span>)
plt.xlabel(<span class="code-string">'Price'</span>)
plt.ylabel(<span class="code-string">'Frequency'</span>)
plt.title(<span class="code-string">'Distribution of Prices'</span>)
plt.show()

<span class="code-comment"># Histogram with multiple datasets for comparison</span>
fig, axes = plt.subplots(<span class="code-number">1</span>, <span class="code-number">2</span>, figsize=(<span class="code-number">14</span>, <span class="code-number">5</span>))

<span class="code-comment"># Original distribution</span>
axes[<span class="code-number">0</span>].hist(df[<span class="code-string">'price'</span>], bins=<span class="code-number">30</span>, edgecolor=<span class="code-string">'black'</span>)
axes[<span class="code-number">0</span>].set_title(<span class="code-string">'Original Distribution'</span>)
axes[<span class="code-number">0</span>].set_xlabel(<span class="code-string">'Price'</span>)

<span class="code-comment"># Log-transformed distribution (for skewed data)</span>
axes[<span class="code-number">1</span>].hist(np.log1p(df[<span class="code-string">'price'</span>]), bins=<span class="code-number">30</span>, edgecolor=<span class="code-string">'black'</span>)
axes[<span class="code-number">1</span>].set_title(<span class="code-string">'Log-Transformed Distribution'</span>)
axes[<span class="code-number">1</span>].set_xlabel(<span class="code-string">'Log(Price)'</span>)

plt.tight_layout()
plt.show()

<span class="code-comment"># Using Seaborn for prettier histograms with KDE</span>
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns

plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">6</span>))
sns.histplot(data=df, x=<span class="code-string">'price'</span>, kde=<span class="code-keyword">True</span>, bins=<span class="code-number">30</span>)
<span class="code-comment"># kde=True overlays kernel density estimate (smooth curve)</span>
plt.title(<span class="code-string">'Distribution with Density Curve'</span>)
plt.show()

<span class="code-comment"># Separate histograms by category to find distinct groups</span>
fig, ax = plt.subplots(figsize=(<span class="code-number">12</span>, <span class="code-number">6</span>))
<span class="code-keyword">for</span> category <span class="code-keyword">in</span> df[<span class="code-string">'category'</span>].unique():
    subset = df[df[<span class="code-string">'category'</span>] == category]
    ax.hist(subset[<span class="code-string">'price'</span>], alpha=<span class="code-number">0.5</span>, label=category, bins=<span class="code-number">20</span>)
ax.legend()
ax.set_xlabel(<span class="code-string">'Price'</span>)
ax.set_ylabel(<span class="code-string">'Frequency'</span>)
ax.set_title(<span class="code-string">'Price Distribution by Category'</span>)
plt.show()
      </code-block>
    </div>

    <div class="concept-card" style="--card-accent: var(--warm);">
      <div class="concept-title">üì¶ Box Plots: Outliers and Quartiles Visualized</div>
      <div class="concept-body">
        <p>A box plot is a compact visualization that shows distribution shape and outliers simultaneously. The box extends from the 25th percentile to the 75th percentile‚Äîthe middle half of your data. The line inside the box is the median. The "whiskers" extend to show the range of normal values. Any points beyond the whiskers are displayed individually as potential outliers. This single visualization communicates a lot about your data: where the center is, how spread out it is, whether there are outliers, and whether the distribution is symmetric.</p>

        <p>Box plots are particularly useful for comparing distributions across groups. You can place box plots side by side for different categories and immediately see differences. One category might have much higher values than another. One might have more outliers. One might be more spread out. These comparisons would require much more thought if you only looked at statistics; the visualization makes them obvious.</p>

        <p>The definition of outliers used in box plots is practical and useful: any value more than 1.5 times the interquartile range beyond the quartiles is flagged as a potential outlier. This is not the only definition‚Äîyou can define outliers statistically in many ways‚Äîbut it's a reasonable one that catches many actual errors while not being too aggressive in flagging legitimate extreme values.</p>
      </div>

      <div class="code-block">
<span class="code-comment"># Creating box plots to visualize distributions and outliers</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

df = pd.read_csv(<span class="code-string">'data.csv'</span>)

<span class="code-comment"># Simple box plot for one variable</span>
plt.figure(figsize=(<span class="code-number">8</span>, <span class="code-number">6</span>))
plt.boxplot(df[<span class="code-string">'price'</span>])
plt.ylabel(<span class="code-string">'Price'</span>)
plt.title(<span class="code-string">'Box Plot of Prices'</span>)
plt.show()

<span class="code-comment"># Box plots for multiple groups (comparing distributions)</span>
plt.figure(figsize=(<span class="code-number">12</span>, <span class="code-number">6</span>))
sns.boxplot(data=df, x=<span class="code-string">'category'</span>, y=<span class="code-string">'price'</span>)
plt.title(<span class="code-string">'Price Distribution by Category'</span>)
plt.show()

<span class="code-comment"># Identify outliers programmatically using IQR method</span>
Q1 = df[<span class="code-string">'price'</span>].quantile(<span class="code-number">0.25</span>)
Q3 = df[<span class="code-string">'price'</span>].quantile(<span class="code-number">0.75</span>)
IQR = Q3 - Q1

<span class="code-comment"># Define outlier boundaries</span>
lower_bound = Q1 - <span class="code-number">1.5</span> * IQR
upper_bound = Q3 + <span class="code-number">1.5</span> * IQR

<span class="code-comment"># Find outliers</span>
outliers = df[(df[<span class="code-string">'price'</span>] < lower_bound) | (df[<span class="code-string">'price'</span>] > upper_bound)]
<span class="code-function">print</span>(<span class="code-string">f"Found {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}% of data)"</span>)

<span class="code-comment"># Horizontal box plot (easier to read category names)</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">8</span>))
sns.boxplot(data=df, y=<span class="code-string">'neighborhood'</span>, x=<span class="code-string">'price'</span>, orient=<span class="code-string">'h'</span>)
plt.title(<span class="code-string">'Price by Neighborhood'</span>)
plt.show()
      </code-block>
    </div>

    <div class="impact-box">
      <div class="impact-grid">
        <div class="impact-item" style="--impact-color: var(--warm);">
          <div class="impact-item-title">üéØ Where It's Used</div>
          <div class="impact-item-content">Visualization is how professionals understand data. Before any modeling, you create these plots. During model debugging, visualizations reveal what went wrong. When communicating findings, visualizations make patterns obvious that would be invisible in statistics alone.</div>
        </div>
        <div class="impact-item" style="--impact-color: var(--accent);">
          <div class="impact-item-title">üí° Why It Matters</div>
          <div class="impact-item-content">The human brain is exceptional at visual pattern recognition. A histogram reveals distribution shape instantly. A box plot comparison shows differences immediately. These insights would require extensive thought if you only had statistics. Visualization transforms data from abstract numbers into understandable patterns.</div>
        </div>
        <div class="impact-item" style="--impact-color: var(--cool);">
          <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
          <div class="impact-item-content">During initial exploration, create histograms for every numerical column. Create box plots to compare groups. Create these visualizations before cleaning data to understand what you're working with. Recreate them after cleaning to verify nothing went wrong. Visualization should be automatic in your workflow.</div>
        </div>
      </div>
    </div>

  </section>

  <section id="relationships">
    <div class="section-label">Understanding Connections</div>
    <h2 class="section-title">Relationships: Scatter Plots, Correlation, and Covariance</h2>

    <div class="concept-card" style="--card-accent: var(--hot);">
      <div class="concept-title">üìç Scatter Plots: Visualizing Relationships</div>
      <div class="concept-body">
        <p>A scatter plot shows the relationship between two variables by plotting them against each other. Each point represents one observation. By looking at the pattern of points, you see immediately whether there's a relationship, what kind of relationship it is, and how strong it is. Do the points form a clear linear pattern? Is the relationship nonlinear? Are there distinct clusters suggesting hidden groups? Are there unusual points that stand out?</p>

        <p>Scatter plots reveal relationships that correlation coefficients hide. Imagine four datasets with identical correlation of 0.816. Their scatter plots would look completely different: one shows a clear linear relationship, one shows a perfect curve, one shows points clustered except for one outlier pulling the relationship up, and one shows a mostly horizontal cloud. You cannot understand relationships properly without visualizing them. This is the essential lesson of Anscombe's Quartet: always visualize your data.</p>

        <p>Scatter plots also reveal what kind of preprocessing your data needs. If you see a curved relationship, you might transform variables before modeling. If you see distinct clusters, you might create a categorical variable to identify them. If you see one point far from others, you've found a potential outlier to investigate. The visualization gives you information that statistics alone cannot provide.</p>
      </div>

      <div class="code-block">
<span class="code-comment"># Creating scatter plots to visualize relationships</span>
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

df = pd.read_csv(<span class="code-string">'data.csv'</span>)

<span class="code-comment"># Simple scatter plot</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">6</span>))
plt.scatter(df[<span class="code-string">'square_feet'</span>], df[<span class="code-string">'price'</span>], alpha=<span class="code-number">0.5</span>)
plt.xlabel(<span class="code-string">'Square Feet'</span>)
plt.ylabel(<span class="code-string">'Price'</span>)
plt.title(<span class="code-string">'House Price vs Size'</span>)
plt.show()

<span class="code-comment"># Scatter plot with regression line showing trend</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">6</span>))
sns.regplot(data=df, x=<span class="code-string">'square_feet'</span>, y=<span class="code-string">'price'</span>, scatter_kws={<span class="code-string">'alpha'</span>: <span class="code-number">0.5</span>})
plt.xlabel(<span class="code-string">'Square Feet'</span>)
plt.ylabel(<span class="code-string">'Price'</span>)
plt.title(<span class="code-string">'House Price vs Size with Trend'</span>)
plt.show()

<span class="code-comment"># Scatter plot colored by category to find distinct groups</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">6</span>))
<span class="code-keyword">for</span> category <span class="code-keyword">in</span> df[<span class="code-string">'category'</span>].unique():
    subset = df[df[<span class="code-string">'category'</span>] == category]
    plt.scatter(subset[<span class="code-string">'square_feet'</span>], subset[<span class="code-string">'price'</span>], 
                label=category, alpha=<span class="code-number">0.6</span>, s=<span class="code-number">50</span>)
plt.xlabel(<span class="code-string">'Square Feet'</span>)
plt.ylabel(<span class="code-string">'Price'</span>)
plt.legend()
plt.title(<span class="code-string">'House Price vs Size by Category'</span>)
plt.show()

<span class="code-comment"># Matrix of scatter plots (pairplot) to see all relationships</span>
<span class="code-comment"># Only for a subset to avoid overwhelming visualization</span>
cols = [<span class="code-string">'price'</span>, <span class="code-string">'square_feet'</span>, <span class="code-string">'age'</span>, <span class="code-string">'bedrooms'</span>]
sns.pairplot(df[cols], diag_kind=<span class="code-string">'hist'</span>)
<span class="code-comment"># Diagonal shows distributions, off-diagonal shows relationships</span>
plt.show()
      </code-block>
    </div>

    <div class="concept-card" style="--card-accent: var(--accent);">
      <div class="concept-title">üìä Correlation and Covariance: Measuring Relationships</div>
      <div class="concept-body">
        <p>While visualizations are essential, numerical measures of relationship strength are also important. Correlation quantifies how two variables move together. A correlation of +1 means perfect positive relationship: when one increases, the other increases proportionally. A correlation of -1 means perfect negative relationship: when one increases, the other decreases. A correlation of 0 means no linear relationship. Most real relationships fall somewhere between these extremes.</p>

        <p>Covariance is similar to correlation but uses different units. Covariance depends on the scale of variables. If you measure one variable in meters and another in kilometers, the covariance changes even if the underlying relationship doesn't. Correlation is scale-independent, making it more interpretable. This is why correlation is used more commonly: the -1 to +1 range is easier to interpret regardless of variable units.</p>

        <p>An important caveat: correlation measures linear relationships. Two variables can have a curved relationship with correlation near zero, even though they're clearly related. This is why you must visualize before trusting correlation numbers. The famous case of computing correlation between ice cream sales and drowning deaths seems to show a strong relationship, but it's spurious‚Äîboth are caused by warm weather. Correlation without causal reasoning is dangerous.</p>

        <p>A correlation matrix shows all pairwise correlations between variables in a table. When the matrix is large, a heatmap (colored grid) makes it easy to spot which variables are related. Positive correlations appear in warm colors, negative in cool colors, with intensity showing strength. This visualization quickly reveals which variables might be redundant or which pairs are related.</p>
      </div>

      <div class="code-block">
<span class="code-comment"># Computing and visualizing correlations</span>
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns

df = pd.read_csv(<span class="code-string">'data.csv'</span>)

<span class="code-comment"># Compute correlation between two specific variables</span>
corr_two = df[<span class="code-string">'price'</span>].corr(df[<span class="code-string">'square_feet'</span>])
<span class="code-function">print</span>(<span class="code-string">f"Correlation between price and square_feet: {corr_two:.3f}"</span>)

<span class="code-comment"># Compute correlation matrix (all pairwise correlations)</span>
numeric_df = df.select_dtypes(include=[np.number])  <span class="code-comment"># Keep only numeric columns</span>
corr_matrix = numeric_df.corr()
<span class="code-function">print</span>(corr_matrix)  <span class="code-comment"># Print full matrix</span>

<span class="code-comment"># Find correlations with target variable</span>
target_correlations = corr_matrix[<span class="code-string">'price'</span>].sort_values(ascending=<span class="code-keyword">False</span>)
<span class="code-function">print</span>(<span class="code-string">"Features most correlated with price:"</span>)
<span class="code-function">print</span>(target_correlations)

<span class="code-comment"># Visualize correlation matrix as heatmap</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">8</span>))
sns.heatmap(corr_matrix, annot=<span class="code-keyword">True</span>, cmap=<span class="code-string">'coolwarm'</span>, center=<span class="code-number">0</span>, 
            fmt=<span class="code-string">'.2f'</span>, square=<span class="code-keyword">True</span>)
<span class="code-comment"># Red = positive correlation, Blue = negative correlation</span>
plt.title(<span class="code-string">'Correlation Matrix Heatmap'</span>)
plt.show()

<span class="code-comment"># Find pairs with high correlation (potential redundancy)</span>
<span class="code-comment"># Useful for feature selection: redundant features can be removed</span>
<span class="code-function">print</span>(<span class="code-string">"Highly correlated variable pairs:"</span>)
<span class="code-keyword">for</span> i <span class="code-keyword">in</span> <span class="code-function">range</span>(<span class="code-function">len</span>(corr_matrix.columns)):
    <span class="code-keyword">for</span> j <span class="code-keyword">in</span> <span class="code-function">range</span>(i+<span class="code-number">1</span>, <span class="code-function">len</span>(corr_matrix.columns)):
        <span class="code-keyword">if</span> <span class="code-function">abs</span>(corr_matrix.iloc[i, j]) > <span class="code-number">0.8</span>:  <span class="code-comment"># Correlation above 0.8</span>
            var1 = corr_matrix.columns[i]
            var2 = corr_matrix.columns[j]
            corr_value = corr_matrix.iloc[i, j]
            <span class="code-function">print</span>(<span class="code-string">f"{var1} <-> {var2}: {corr_value:.3f}"</span>)
      </code-block>
    </div>

    <div class="impact-box">
      <div class="impact-grid">
        <div class="impact-item" style="--impact-color: var(--hot);">
          <div class="impact-item-title">üéØ Where It's Used</div>
          <div class="impact-item-content">Understanding relationships guides feature selection and engineering. High correlations between features suggest redundancy‚Äîyou might remove one. Relationships with the target variable guide which features are important. Unusual scatter patterns suggest the need for variable transformation or interaction terms.</div>
        </div>
        <div class="impact-item" style="--impact-color: var(--green);">
          <div class="impact-item-title">üí° Why It Matters</div>
          <div class="impact-item-content">Relationships determine what models can learn. Strong linear relationships might suggest linear models work well. Complex nonlinear relationships suggest you need more sophisticated algorithms. Redundant features waste model capacity. Understanding relationships prevents these mistakes.</div>
        </div>
        <div class="impact-item" style="--impact-color: var(--cool);">
          <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
          <div class="impact-item-content">During exploration, create scatter plots and compute correlations for all variable pairs. Create correlation matrices and heatmaps to understand the relationship landscape. Use this understanding to decide which variables to keep, which to transform, and which combinations might be useful.</div>
        </div>
      </div>
    </div>

  </section>

  <section id="workflow">
    <div class="section-label">Putting It All Together</div>
    <h2 class="section-title">The Data Exploration Workflow in Practice</h2>

    <div class="timeline">
      <div class="timeline-item">
        <div class="timeline-title">Load and Inspect Data Structure</div>
        <div class="timeline-desc">Start by loading data and examining its basic structure. How many rows and columns? What are the data types? Use head(), info(), and shape to understand what you're working with. This tells you whether data loaded correctly and gives you a first impression of what's there.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Compute Descriptive Statistics</div>
        <div class="timeline-desc">Run describe() to get mean, median, standard deviation, and percentiles for numerical columns. These numbers give you the quantitative story of your data. Compare mean and median to understand skewness. Notice which values have extreme ranges compared to others. This foundation guides everything afterward.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Visualize Distributions</div>
        <div class="timeline-desc">Create histograms for each numerical variable. Look at the shapes. Are they bell-shaped, skewed, bimodal? Create box plots to check for outliers and compare distributions across groups. These visualizations reveal patterns that statistics alone cannot show.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Investigate Relationships</div>
        <div class="timeline-desc">Create scatter plots between variables you suspect are related. Compute correlation matrices and visualize as heatmaps. This reveals which variables are linked, which might be redundant, and which patterns exist. This understanding informs feature engineering decisions.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Check Data Quality Issues</div>
        <div class="timeline-desc">Look for missing values in your exploration. Check for outliers and investigate whether they're errors or genuine. Examine categorical variables to understand their distribution and consistency. Document quality issues you find. This knowledge guides your cleaning approach.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Segment and Compare Groups</div>
        <div class="timeline-desc">Group data by categorical variables and compare statistics across groups. Are some groups very different from others? Do patterns differ by group? This reveals whether group-specific preprocessing or modeling might be needed. It surfaces hidden structures in your data.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Document Insights and Decisions</div>
        <div class="timeline-desc">Record what you've learned. Which variables need transformation? Which are most related to your target? Which might be redundant? What preprocessing steps does the data need? This documentation guides your preprocessing and modeling approach. It explains the choices you made to others reading your work.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Plan Preprocessing and Feature Engineering</div>
        <div class="timeline-desc">Based on exploration, plan your approach. Which variables need normalization based on their distributions? Which need transformation for nonlinear relationships? Which interactions might matter? Which features should you engineer based on patterns you discovered? Exploration drives these decisions.</div>
      </div>
    </div>

  </section>

  <section>
    <div class="section-label">The Heart of Understanding</div>
    <h2 class="section-title">Why Exploration Matters More Than You Might Think</h2>

    <div class="insight-box" style="--insight-color: var(--cool);">
      <div class="insight-title">Exploration is where understanding lives</div>
      <div class="insight-content">Data exploration isn't just a preliminary step before "real" data science. It's where genuine understanding is built. When you compute statistics, create visualizations, and investigate relationships, you're not just executing mechanical tasks. You're developing an intuitive understanding of your data‚Äîwhat patterns exist, which variables matter, what preprocessing will help, what algorithms might work. This understanding is irreplaceable. You cannot build good models without it. You cannot trust your results without it. You cannot explain your findings to others without it. The time you invest in exploration pays back repeatedly throughout your entire project. Professionals allocate significant time to exploration. Beginners rush through it. This difference is one reason professionals build models that work while beginners build models that barely work.</div>
    </div>

    <div class="insight-box" style="--insight-color: var(--green);">
      <div class="insight-title">Visualization reveals what statistics hide</div>
      <div class="insight-content">Anscombe's Quartet should be permanently etched in your mind. Four datasets with identical mean, variance, correlation, and regression line look completely different when visualized. One shows a perfect linear relationship. One shows a perfect curve. One shows a horizontal line with one outlier pulling the regression line up. One shows complete randomness. These would lead to completely different modeling decisions. You cannot trust statistics alone. You must visualize. Visualization is how the human brain, which evolved to recognize visual patterns, interfaces with data. Exploit this strength. Create visualizations even when you think you don't need them. They will reveal surprises.</div>
    </div>

    <div class="insight-box" style="--insight-color: var(--warm);">
      <div class="insight-title">Questions guide exploration, not the reverse</div>
      <div class="insight-content">Exploratory data analysis isn't wandering randomly through data hoping to find something. It's asking specific questions and using statistics and visualization to answer them. What values appear most frequently? What's the range of variation? Do relationships exist between variables? Do groups differ systematically? By asking questions, you make exploration focused and efficient. You're not just looking at plots hoping something jumps out. You're investigating specific hypotheses. This systematic approach makes exploration rigorous rather than haphazard. It ensures you discover important patterns rather than getting distracted by noise.</div>
    </div>

  </section>

</div>

<footer>
  <p class="footer-text">Data Exploration and Analysis ‚Äî The Foundation of Data-Driven Insight</p>
</footer>

</body>
</html>
