<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Essential Python Libraries ‚Äî The ML Developer's Toolkit</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Bebas+Neue&family=DM+Mono:wght@400;500&family=Clash+Display:wght@400;600;700&display=swap');
@import url('https://fonts.googleapis.com/css2?family=Syne:wght@400;600;700;800&family=Syne+Mono&display=swap');

:root {
  --bg: #04040a;
  --accent: #7b2fff;
  --hot: #ff2d78;
  --cool: #00e5ff;
  --warm: #ffb800;
  --green: #00ff9d;
  --text: #e0e0f0;
  --muted: #4a4a6a;
  --card: #0a0a14;
  --border: rgba(255,255,255,0.07);
}

* { box-sizing: border-box; margin: 0; padding: 0; }
html { scroll-behavior: smooth; }

body {
  background: var(--bg);
  color: var(--text);
  font-family: 'Syne', sans-serif;
  overflow-x: hidden;
  line-height: 1.8;
}

/* Starfield bg */
body::before {
  content: '';
  position: fixed; inset: 0; z-index: 0;
  background:
    radial-gradient(ellipse 100% 60% at 50% 0%, rgba(123,47,255,0.12) 0%, transparent 60%),
    radial-gradient(ellipse 60% 40% at 0% 100%, rgba(0,229,255,0.06) 0%, transparent 60%);
  pointer-events: none;
}

.wrap { position: relative; z-index: 1; max-width: 1100px; margin: 0 auto; padding: 0 28px; }

/* NAV */
nav {
  position: sticky; top: 0; z-index: 100;
  background: rgba(4,4,10,0.9);
  backdrop-filter: blur(24px);
  border-bottom: 1px solid var(--border);
  padding: 14px 28px;
  display: flex; align-items: center; gap: 10px; flex-wrap: wrap;
}
.nav-brand { font-family: 'Bebas Neue', sans-serif; font-size: 20px; color: var(--accent); margin-right: auto; letter-spacing: 2px; }
.nav-pill {
  font-family: 'Syne Mono', monospace; font-size: 10px; letter-spacing: 2px;
  padding: 5px 12px; border-radius: 20px; border: 1px solid rgba(123,47,255,0.4);
  color: rgba(123,47,255,0.8); text-decoration: none; transition: all 0.2s;
}
.nav-pill:hover, .nav-pill.active { background: rgba(123,47,255,0.15); border-color: var(--accent); color: #fff; }

/* HERO */
.hero { padding: 90px 0 50px; }
.hero-eyebrow {
  font-family: 'Syne Mono', monospace; font-size: 11px; letter-spacing: 4px;
  color: var(--accent); text-transform: uppercase; margin-bottom: 18px;
  display: flex; align-items: center; gap: 12px;
}
.hero-eyebrow::after { content: ''; flex: 1; height: 1px; background: rgba(123,47,255,0.3); }

.hero h1 {
  font-family: 'Bebas Neue', sans-serif;
  font-size: clamp(48px, 10vw, 100px);
  line-height: 0.92; margin-bottom: 28px;
  color: #fff;
}

.hero-desc { max-width: 750px; font-size: 16px; color: rgba(210,210,240,0.72); line-height: 1.8; margin-bottom: 40px; }

/* SECTION */
section { padding: 70px 0; border-top: 1px solid var(--border); }
.section-label { font-family: 'Syne Mono', monospace; font-size: 10px; letter-spacing: 4px; color: var(--accent); text-transform: uppercase; margin-bottom: 16px; }
.section-title { font-family: 'Bebas Neue', sans-serif; font-size: clamp(36px, 6vw, 64px); line-height: 1; margin-bottom: 40px; color: #fff; }

/* LIBRARY CARD */
.library-card {
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 16px;
  padding: 40px;
  margin-bottom: 36px;
  border-left: 4px solid var(--lib-color, var(--accent));
  transition: all 0.3s;
}

.library-card:hover {
  border-color: var(--lib-color, var(--accent));
  background: linear-gradient(135deg, rgba(255,255,255,0.02) 0%, transparent 100%);
  transform: translateY(-2px);
}

.lib-header {
  display: flex;
  align-items: center;
  gap: 20px;
  margin-bottom: 28px;
}

.lib-icon {
  font-size: 48px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.lib-title-section h2 {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 32px;
  color: var(--lib-color, var(--accent));
  margin-bottom: 8px;
  letter-spacing: 1px;
}

.lib-tagline {
  font-size: 14px;
  color: rgba(200,200,220,0.8);
  font-style: italic;
}

.lib-body {
  font-size: 15px;
  color: rgba(210,210,240,0.88);
  line-height: 1.9;
  margin-bottom: 28px;
}

.lib-body p {
  margin-bottom: 16px;
}

.lib-body strong {
  color: #fff;
}

.code-block {
  background: rgba(0,0,0,0.5);
  border: 1px solid rgba(0,229,255,0.2);
  border-radius: 12px;
  padding: 24px;
  margin: 24px 0;
  font-family: 'DM Mono', monospace;
  font-size: 13px;
  color: #fff;
  overflow-x: auto;
  line-height: 1.6;
}

.code-comment {
  color: #5c7a8a;
}

.code-keyword {
  color: var(--accent);
}

.code-string {
  color: var(--green);
}

.code-number {
  color: var(--warm);
}

.code-function {
  color: var(--cool);
}

.teaching-box {
  background: rgba(123,47,255,0.1);
  border-left: 4px solid var(--accent);
  padding: 20px;
  border-radius: 10px;
  margin: 24px 0;
  font-size: 14px;
  color: rgba(210,210,240,0.9);
  line-height: 1.8;
}

.teaching-box strong {
  color: #fff;
}

.core-functions {
  background: rgba(0,0,0,0.3);
  border: 1px solid rgba(255,255,255,0.08);
  border-radius: 12px;
  padding: 28px;
  margin: 24px 0;
}

.functions-title {
  font-family: 'Syne Mono', monospace;
  font-size: 11px;
  letter-spacing: 2px;
  color: var(--lib-color, var(--accent));
  text-transform: uppercase;
  margin-bottom: 16px;
  font-weight: 600;
}

.function-list {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
  gap: 16px;
}

.function-item {
  background: rgba(0,0,0,0.4);
  padding: 14px;
  border-radius: 8px;
  border-left: 3px solid var(--lib-color, var(--accent));
}

.function-name {
  font-family: 'DM Mono', monospace;
  font-size: 12px;
  color: var(--lib-color, var(--accent));
  margin-bottom: 6px;
  font-weight: 600;
}

.function-desc {
  font-size: 12px;
  color: rgba(200,200,220,0.8);
  line-height: 1.6;
}

/* IMPACT BOX */
.impact-box {
  background: linear-gradient(135deg, rgba(123,47,255,0.15) 0%, rgba(0,229,255,0.08) 100%);
  border: 1px solid rgba(123,47,255,0.3);
  border-radius: 14px;
  padding: 32px;
  margin-top: 32px;
}

.impact-grid {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
  gap: 28px;
}

.impact-item {
  padding: 24px;
  background: rgba(0,0,0,0.2);
  border-radius: 10px;
  border-left: 4px solid var(--impact-color, var(--accent));
}

.impact-item-title {
  font-family: 'Syne Mono', monospace;
  font-size: 12px;
  letter-spacing: 2px;
  color: var(--impact-color, var(--accent));
  text-transform: uppercase;
  margin-bottom: 14px;
  font-weight: 600;
}

.impact-item-content {
  font-size: 13px;
  color: rgba(200,200,220,0.88);
  line-height: 1.8;
}

/* ECOSYSTEM MAP */
.ecosystem-section {
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 12px;
  padding: 32px;
  margin: 40px 0;
}

.ecosystem-title {
  font-family: 'Syne Mono', monospace;
  font-size: 11px;
  letter-spacing: 2px;
  color: var(--warm);
  text-transform: uppercase;
  margin-bottom: 20px;
}

.ecosystem-description {
  font-size: 14px;
  color: rgba(210,210,240,0.88);
  line-height: 1.8;
  margin-bottom: 20px;
}

.ecosystem-flow {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 16px;
  margin-top: 24px;
}

.flow-item {
  background: rgba(0,0,0,0.3);
  padding: 16px;
  border-radius: 8px;
  border-top: 3px solid var(--warm);
  font-size: 13px;
  color: rgba(200,200,220,0.9);
}

.flow-label {
  font-family: 'Syne Mono', monospace;
  font-size: 10px;
  color: var(--warm);
  margin-bottom: 8px;
  font-weight: 600;
}

/* COMPARISON TABLE */
.comparison-section {
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 12px;
  overflow: hidden;
  margin: 32px 0;
}

.table-header {
  background: rgba(123,47,255,0.15);
  padding: 24px;
  border-bottom: 1px solid var(--border);
  display: grid;
  grid-template-columns: 1fr 1.5fr;
  gap: 20px;
}

.table-row {
  padding: 20px 24px;
  border-bottom: 1px solid var(--border);
  display: grid;
  grid-template-columns: 1fr 1.5fr;
  gap: 20px;
}

.table-row:last-child {
  border-bottom: none;
}

.table-row:nth-child(even) {
  background: rgba(0,0,0,0.1);
}

.table-label {
  font-family: 'Syne Mono', monospace;
  font-size: 12px;
  color: var(--cool);
  font-weight: 600;
}

.table-content {
  font-size: 13px;
  color: rgba(200,200,220,0.85);
  line-height: 1.6;
}

/* TIMELINE */
.timeline {
  position: relative;
  padding: 40px 0;
}

.timeline-item {
  padding: 28px;
  background: var(--card);
  border: 1px solid var(--border);
  border-radius: 10px;
  margin-bottom: 24px;
  margin-left: 40px;
  position: relative;
}

.timeline-item::before {
  content: '';
  position: absolute;
  left: -32px;
  top: 32px;
  width: 16px;
  height: 16px;
  background: var(--accent);
  border-radius: 50%;
  border: 3px solid var(--bg);
}

.timeline-item::after {
  content: '';
  position: absolute;
  left: -24px;
  top: 48px;
  width: 2px;
  height: 44px;
  background: rgba(123,47,255,0.3);
}

.timeline-item:last-child::after {
  display: none;
}

.timeline-title {
  font-family: 'Bebas Neue', sans-serif;
  font-size: 18px;
  color: var(--cool);
  margin-bottom: 10px;
  letter-spacing: 1px;
}

.timeline-desc {
  font-size: 14px;
  color: rgba(200,200,220,0.85);
  line-height: 1.8;
}

/* FOOTER */
footer {
  padding: 60px 0 40px;
  border-top: 1px solid var(--border);
  text-align: center;
}

.footer-text {
  font-family: 'Syne Mono', monospace;
  font-size: 11px;
  letter-spacing: 2px;
  color: var(--muted);
  text-transform: uppercase;
}

/* RESPONSIVE */
@media (max-width: 768px) {
  .hero { padding: 60px 0 40px; }
  section { padding: 50px 0; }
  .lib-header { flex-direction: column; align-items: flex-start; }
  .impact-grid { grid-template-columns: 1fr; }
  .table-header, .table-row { grid-template-columns: 1fr; }
}

</style>
</head>
<body>

<nav>
  <div class="nav-brand">PYTHON LIBRARIES</div>
  <a href="#numpy" class="nav-pill">NumPy</a>
  <a href="#pandas" class="nav-pill">Pandas</a>
  <a href="#visualization" class="nav-pill">Visualization</a>
  <a href="#scikit-learn" class="nav-pill">Scikit-learn</a>
</nav>

<div class="wrap">

  <!-- HERO -->
  <section class="hero">
    <div class="hero-eyebrow">Standing on the Shoulders of Giants</div>
    <h1>Essential Python Libraries</h1>
    <p class="hero-desc">Python is powerful not because of the language itself, but because of its ecosystem. Libraries built by thousands of developers solve problems you would otherwise need to tackle from scratch. NumPy provides numerical computing with arrays and linear algebra. Pandas handles data manipulation and exploration. Matplotlib and Seaborn create visualizations that reveal patterns. Scikit-learn provides classical machine learning algorithms. SciPy offers advanced scientific computing. These libraries are the toolkit that transforms Python from a general-purpose language into a machine learning powerhouse. Understanding them deeply is understanding how modern AI systems are built.</p>
  </section>

  <!-- INTRODUCTION -->
  <section>
    <div class="section-label">The Foundation</div>
    <h2 class="section-title">Why Libraries Matter</h2>

    <div class="ecosystem-section">
      <div class="ecosystem-title">The ML Development Stack</div>
      <div class="ecosystem-description">
        Machine learning development involves working at different abstraction levels. At the lowest level, you need efficient numerical operations on arrays‚Äîthat's NumPy. Above that, you need data manipulation and exploration‚Äîthat's Pandas. For visualization and understanding data patterns, you use Matplotlib and Seaborn. For implementing classical ML algorithms, Scikit-learn provides battle-tested implementations. For advanced scientific computing, SciPy offers specialized algorithms. For accessing external data, Requests handles HTTP communication. Each library solves specific problems well, and together they form a complete ecosystem for ML development.
      </div>
      <div class="ecosystem-flow">
        <div class="flow-item">
          <div class="flow-label">Data Loading</div>
          Pandas reads CSV files, JSON, databases. Requests fetches data from web APIs.
        </div>
        <div class="flow-item">
          <div class="flow-label">Exploration</div>
          Pandas provides data inspection. Matplotlib and Seaborn create exploratory visualizations.
        </div>
        <div class="flow-item">
          <div class="flow-label">Preprocessing</div>
          NumPy and Pandas clean and transform data. Scikit-learn provides preprocessing utilities.
        </div>
        <div class="flow-item">
          <div class="flow-label">Modeling</div>
          Scikit-learn for classical ML. PyTorch/TensorFlow build on NumPy concepts for deep learning.
        </div>
        <div class="flow-item">
          <div class="flow-label">Evaluation</div>
          Scikit-learn provides metrics. Matplotlib visualizes results.
        </div>
        <div class="flow-item">
          <div class="flow-label">Deployment</div>
          Models saved and loaded using each library's tools. Predictions served using the same interfaces.
        </div>
      </div>
    </div>

  </section>

  <!-- NUMPY -->
  <section id="numpy">
    <div class="section-label">Numerical Foundation</div>
    <h2 class="section-title">NumPy: Efficient Arrays and Linear Algebra</h2>

    <div class="library-card" style="--lib-color: var(--green);">
      <div class="lib-header">
        <div class="lib-icon">üßÆ</div>
        <div class="lib-title-section">
          <h2>NumPy</h2>
          <div class="lib-tagline">Fundamental package for numerical computing with Python</div>
        </div>
      </div>

      <div class="lib-body">
        NumPy is the foundation of the entire scientific Python ecosystem. It introduces the array data structure, which is fundamentally different from Python lists. While a Python list can contain mixed types and is flexible, a NumPy array is a fixed-size, fixed-type container of numerical values. This uniformity allows NumPy to be extremely fast‚Äîoperations on arrays are implemented in C and run orders of magnitude faster than Python loops doing the same operations.

        The key insight of NumPy is vectorization. Instead of looping over array elements in Python (slow), you express operations on entire arrays at once, and NumPy handles the loop at the C level (fast). For example, adding two million numbers: a Python list would loop two million times; a NumPy array performs the entire operation almost instantaneously. This speed difference makes the difference between waiting seconds and waiting minutes for your code to run.

        Beyond arrays, NumPy provides tools for linear algebra (matrix multiplication, eigenvalue decomposition), random number generation, and mathematical functions. These are building blocks used by higher-level libraries like Pandas, Scikit-learn, and PyTorch.
      </div>

      <div class="teaching-box">
        <strong>Think of NumPy arrays as optimized containers for numbers.</strong> A Python list is like a general-purpose cargo container that can hold anything. A NumPy array is like a specialized truck for moving aluminum ingots‚Äîdesigned specifically for that job and much more efficient. The specification (all same type, contiguous memory) enables speed.
      </div>

      <div class="code-block">
<span class="code-comment"># NumPy arrays: the core data structure</span>
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Create arrays in various ways</span>
arr1 = np.array([<span class="code-number">1</span>, <span class="code-number">2</span>, <span class="code-number">3</span>, <span class="code-number">4</span>, <span class="code-number">5</span>])           <span class="code-comment"># From list</span>
arr2 = np.zeros((<span class="code-number">3</span>, <span class="code-number">4</span>))                    <span class="code-comment"># 3x4 array of zeros</span>
arr3 = np.arange(<span class="code-number">0</span>, <span class="code-number">10</span>, <span class="code-number">2</span>)              <span class="code-comment"># [0, 2, 4, 6, 8]</span>
arr4 = np.random.randn(<span class="code-number">1000</span>)             <span class="code-comment"># 1000 random numbers</span>

<span class="code-comment"># Vectorized operations: no loops needed!</span>
a = np.array([<span class="code-number">1</span>, <span class="code-number">2</span>, <span class="code-number">3</span>])
b = np.array([<span class="code-number">4</span>, <span class="code-number">5</span>, <span class="code-number">6</span>])

result = a + b                      <span class="code-comment"># [5, 7, 9] - element-wise addition</span>
result = a * b                      <span class="code-comment"># [4, 10, 18] - element-wise multiplication</span>
result = np.dot(a, b)              <span class="code-comment"># 32 - dot product</span>

<span class="code-comment"># Shape and reshaping</span>
matrix = np.arange(<span class="code-number">1</span>, <span class="code-number">13</span>).reshape(<span class="code-number">3</span>, <span class="code-number">4</span>)  <span class="code-comment"># Convert 1D to 3x4</span>

<span class="code-comment"># Advanced operations</span>
transposed = matrix.T               <span class="code-comment"># Transpose</span>
eigen_vals, eigen_vecs = np.linalg.eig(matrix @ matrix.T)  <span class="code-comment"># Eigendecomposition</span>
inverse = np.linalg.inv(matrix)    <span class="code-comment"># Matrix inverse</span>

<span class="code-comment"># Indexing and slicing</span>
row0 = matrix[<span class="code-number">0</span>]                    <span class="code-comment"># First row</span>
col1 = matrix[:, <span class="code-number">1</span>]               <span class="code-comment"># Second column</span>
subset = matrix[<span class="code-number">0</span>:<span class="code-number">2</span>, <span class="code-number">1</span>:<span class="code-number">3</span>]       <span class="code-comment"># Slice: rows 0-1, columns 1-2</span>
      </div>

      <div class="core-functions">
        <div class="functions-title">Core NumPy Functions</div>
        <div class="function-list">
          <div class="function-item">
            <div class="function-name">np.array()</div>
            <div class="function-desc">Create array from list or tuple. Fundamental constructor.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.zeros(), np.ones()</div>
            <div class="function-desc">Create arrays filled with zeros or ones of specified shape.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.arange(), np.linspace()</div>
            <div class="function-desc">Create sequences of numbers. arange uses step size, linspace uses count.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.reshape(), .T</div>
            <div class="function-desc">Reshape arrays or transpose. Fundamental for data transformation.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.dot(), np.matmul()</div>
            <div class="function-desc">Matrix multiplication. Central to linear algebra operations.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.linalg.*</div>
            <div class="function-desc">Linear algebra: eigenvalues, inverses, decompositions, solving systems.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.random.randn(), .choice()</div>
            <div class="function-desc">Generate random numbers. Essential for initializing models and sampling.</div>
          </div>
          <div class="function-item">
            <div class="function-name">np.mean(), .std(), .sum()</div>
            <div class="function-desc">Statistical functions. Compute statistics along axes.</div>
          </div>
        </div>
      </div>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--green);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">Every machine learning library builds on NumPy. Scikit-learn uses NumPy arrays for all data. Pandas DataFrames are built on NumPy underneath. PyTorch tensors are similar to NumPy arrays. Every numerical operation in ML ultimately uses NumPy concepts, even when using higher-level libraries.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--cool);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Speed is everything in machine learning. A naive Python loop processing a million samples takes minutes. NumPy does it in milliseconds. Understanding vectorization changes how you think about programming. It's not just faster‚Äîit's how modern ML systems achieve feasible runtimes.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--warm);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">Constantly in data processing. You'll write NumPy operations daily when working with data. Understanding broadcasting (automatic dimension alignment) and vectorization is essential for productive data work. Even when using higher-level libraries, understanding NumPy underneath helps you write better code.</div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <!-- PANDAS -->
  <section id="pandas">
    <div class="section-label">Data Manipulation and Analysis</div>
    <h2 class="section-title">Pandas: DataFrames and Tabular Data</h2>

    <div class="library-card" style="--lib-color: var(--cool);">
      <div class="lib-header">
        <div class="lib-icon">üìä</div>
        <div class="lib-title-section">
          <h2>Pandas</h2>
          <div class="lib-tagline">Data manipulation and analysis library built on NumPy</div>
        </div>
      </div>

      <div class="lib-body">
        If NumPy gives you arrays, Pandas gives you tables‚Äîthe DataFrame. A DataFrame is like a spreadsheet in code: rows and columns with labeled axes. Unlike NumPy arrays where you access elements by numeric indices, DataFrames let you access columns by name (like a dictionary) and rows by label. This makes data exploration and manipulation intuitive and readable.

        The power of Pandas lies in its tools for data exploration and cleaning. You can load data from CSV files with one line of code. You can inspect structure with `.info()` and `.describe()`, showing you data types and statistics. You can handle missing values, remove duplicates, and transform data. Most machine learning projects spend 70 percent of time in data exploration and cleaning, and Pandas makes this bearable.

        Pandas also integrates seamlessly with NumPy (underneath, DataFrames use NumPy arrays) and plotting libraries. You can quickly visualize data without converting between formats. For most tabular data work, you'll live in Pandas before feeding cleaned data to machine learning libraries.
      </div>

      <div class="teaching-box">
        <strong>Think of Pandas as a programmable spreadsheet.</strong> Just like Excel lets you organize data in rows and columns, Pandas does the same‚Äîbut with a programming interface. You can filter, aggregate, join, and transform data programmatically. It's the bridge between raw data and machine learning models.
      </div>

      <div class="code-block">
<span class="code-keyword">import</span> pandas <span class="code-keyword">as</span> pd

<span class="code-comment"># Load data from CSV</span>
df = pd.read_csv(<span class="code-string">'dataset.csv'</span>)

<span class="code-comment"># Inspect the data structure</span>
<span class="code-function">print</span>(df.head())              <span class="code-comment"># First 5 rows</span>
<span class="code-function">print</span>(df.info())              <span class="code-comment"># Data types and missing values</span>
<span class="code-function">print</span>(df.describe())          <span class="code-comment"># Statistical summary</span>
<span class="code-function">print</span>(df.shape)              <span class="code-comment"># Number of rows and columns</span>

<span class="code-comment"># Access columns and rows</span>
names = df[<span class="code-string">'name'</span>]             <span class="code-comment"># Access column by name (returns Series)</span>
row0 = df.iloc[<span class="code-number">0</span>]              <span class="code-comment"># Access row by numeric index</span>
subset = df[[<span class="code-string">'name'</span>, <span class="code-string">'age'</span>]]  <span class="code-comment"># Access multiple columns</span>

<span class="code-comment"># Filtering and selection</span>
adults = df[df[<span class="code-string">'age'</span>] >= <span class="code-number">18</span>]    <span class="code-comment"># Rows where age >= 18</span>
rich = df[df[<span class="code-string">'salary'</span>] > <span class="code-number">100000</span>]  <span class="code-comment"># Rows where salary > 100000</span>

<span class="code-comment"># Handle missing values</span>
df_clean = df.dropna()              <span class="code-comment"># Remove rows with missing values</span>
df_filled = df.fillna(df.mean())    <span class="code-comment"># Fill with mean of column</span>

<span class="code-comment"># Grouping and aggregation</span>
by_department = df.groupby(<span class="code-string">'department'</span>)[<span class="code-string">'salary'</span>].mean()  <span class="code-comment"># Mean salary per department</span>

<span class="code-comment"># Data transformation</span>
df[<span class="code-string">'age_group'</span>] = pd.cut(df[<span class="code-string">'age'</span>], bins=[<span class="code-number">0</span>, <span class="code-number">18</span>, <span class="code-number">65</span>, <span class="code-number">100</span>])  <span class="code-comment"># Create bins</span>
df[<span class="code-string">'salary_normalized'</span>] = (df[<span class="code-string">'salary'</span>] - df[<span class="code-string">'salary'</span>].mean()) / df[<span class="code-string">'salary'</span>].std()

<span class="code-comment"># Merging datasets</span>
merged = pd.merge(df1, df2, on=<span class="code-string">'id'</span>)  <span class="code-comment"># Join on common column</span>
      </code-block>

      <div class="core-functions">
        <div class="functions-title">Core Pandas Functions</div>
        <div class="function-list">
          <div class="function-item">
            <div class="function-name">pd.read_csv(), read_json()</div>
            <div class="function-desc">Load data from files. First step of almost every ML project.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.head(), .tail(), .info()</div>
            <div class="function-desc">Inspect data. Understanding structure is crucial for cleaning.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.describe(), .value_counts()</div>
            <div class="function-desc">Statistical summary. Understand distributions and patterns.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.dropna(), .fillna()</div>
            <div class="function-desc">Handle missing values. Data is rarely perfect; cleaning is essential.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.groupby(), .agg()</div>
            <div class="function-desc">Group and aggregate. Understand patterns by groups.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.merge(), .join()</div>
            <div class="function-desc">Combine datasets. Often data comes from multiple sources.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.apply(), .map()</div>
            <div class="function-desc">Apply functions to columns. Transform data programmatically.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.to_numpy()</div>
            <div class="function-desc">Convert to NumPy array for machine learning models.</div>
          </div>
        </div>
      </div>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--cool);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">Every machine learning project starts with Pandas. You load data with Pandas, explore with Pandas, clean with Pandas, and then convert to NumPy arrays or other formats for modeling. Kaggle competitions, industry projects, research‚Äîalmost every data scientist spends their workday in Pandas.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--hot);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Data exploration and cleaning determines model quality. You can't build a good model on bad data. Pandas makes this critical phase bearable. It lets you ask questions about your data interactively and get answers instantly. Good data understanding leads to better features and better models.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--green);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">First thing every day. Loading data with Pandas, understanding it, cleaning it, transforming it. This is the majority of ML work. Mastering Pandas means you can efficiently work with any tabular dataset, which is most real-world data.</div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <!-- VISUALIZATION -->
  <section id="visualization">
    <div class="section-label">Understanding Through Visualization</div>
    <h2 class="section-title">Matplotlib and Seaborn: Creating and Understanding Visualizations</h2>

    <div class="library-card" style="--lib-color: var(--warm);">
      <div class="lib-header">
        <div class="lib-icon">üìà</div>
        <div class="lib-title-section">
          <h2>Matplotlib & Seaborn</h2>
          <div class="lib-tagline">Visualization libraries for exploring and communicating data patterns</div>
        </div>
      </div>

      <div class="lib-body">
        Matplotlib is the foundational plotting library. It lets you create line plots, scatter plots, histograms, and any other type of visualization your imagination allows. Matplotlib is powerful but requires a lot of code for polished results. You must specify every detail‚Äîaxes labels, colors, sizes, legends. This gives you complete control but is verbose for common tasks.

        Seaborn is built on top of Matplotlib and handles the tedious parts. It provides beautiful default styles and automates many labeling tasks. More importantly, Seaborn provides statistical visualizations‚Äîheatmaps showing correlations, distribution plots showing relationships, box plots comparing groups. These are the visualizations that matter for data understanding.

        The key insight is that visualization is understanding. A histogram showing a distribution can reveal outliers or normality that summary statistics hide. A scatter plot can reveal relationships between variables that correlation coefficients alone don't capture. A heatmap can show which features are related at a glance. In exploratory data analysis, visualization is how you discover patterns. In communicating results, visualization is how you convince others your findings matter.
      </div>

      <div class="teaching-box">
        <strong>Visualization turns numbers into patterns your brain can immediately recognize.</strong> Your visual cortex is incredibly powerful at pattern recognition. A table of numbers tells you nothing. A plot of those same numbers immediately reveals trends, clusters, and anomalies. This is why every data scientist spends significant time visualizing data.
      </div>

      <div class="code-block">
<span class="code-keyword">import</span> matplotlib.pyplot <span class="code-keyword">as</span> plt
<span class="code-keyword">import</span> seaborn <span class="code-keyword">as</span> sns
<span class="code-keyword">import</span> numpy <span class="code-keyword">as</span> np

<span class="code-comment"># Set style for better-looking plots</span>
sns.set_style(<span class="code-string">"darkgrid"</span>)

<span class="code-comment"># Histogram: distribution of a single variable</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">5</span>))
plt.hist(data, bins=<span class="code-number">30</span>, edgecolor=<span class="code-string">'black'</span>)
plt.xlabel(<span class="code-string">'Values'</span>)
plt.ylabel(<span class="code-string">'Frequency'</span>)
plt.title(<span class="code-string">'Distribution of Data'</span>)
plt.show()

<span class="code-comment"># Scatter plot: relationship between two variables</span>
plt.figure(figsize=(<span class="code-number">8</span>, <span class="code-number">6</span>))
plt.scatter(x, y, alpha=<span class="code-number">0.5</span>)
plt.xlabel(<span class="code-string">'Feature X'</span>)
plt.ylabel(<span class="code-string">'Feature Y'</span>)
plt.title(<span class="code-string">'Scatter Plot'</span>)

<span class="code-comment"># Correlation heatmap: relationships among many variables</span>
plt.figure(figsize=(<span class="code-number">10</span>, <span class="code-number">8</span>))
sns.heatmap(df.corr(), annot=<span class="code-keyword">True</span>, cmap=<span class="code-string">'coolwarm'</span>)
plt.title(<span class="code-string">'Correlation Matrix'</span>)

<span class="code-comment"># Box plot: comparing distributions across groups</span>
sns.boxplot(data=df, x=<span class="code-string">'category'</span>, y=<span class="code-string">'value'</span>)
plt.title(<span class="code-string">'Values by Category'</span>)

<span class="code-comment"># Distribution plot: detailed view of single distribution</span>
sns.distplot(data, kde=<span class="code-keyword">True</span>, hist=<span class="code-keyword">True</span>)
plt.title(<span class="code-string">'Distribution with KDE'</span>)
      </code-block>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--warm);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">Exploratory data analysis requires visualization. Understanding feature distributions, finding outliers, identifying relationships‚Äîall revealed through plots. Communicating results to stakeholders requires visualization. Raw numbers don't convince; clear visualizations do. Every data science notebook has plots.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--accent);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Visualization reveals what summary statistics hide. Outliers, non-linear relationships, multimodal distributions‚Äîall obvious in plots, invisible in means and standard deviations. Bad data quality (missing values, duplicates) becomes obvious in distributions. Feature engineering ideas emerge from visualizations.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--cool);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">Constantly during exploration. Before building any model, visualize your data. After building models, visualize predictions and errors. Communicating with non-technical stakeholders‚Äîuse visualizations. The only time visualization doesn't matter is if you're completely confident about data quality and relationships, which is never.</div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <!-- SCIKIT-LEARN -->
  <section id="scikit-learn">
    <div class="section-label">Machine Learning Algorithms</div>
    <h2 class="section-title">Scikit-learn: Classical ML Algorithms</h2>

    <div class="library-card" style="--lib-color: var(--hot);">
      <div class="lib-header">
        <div class="lib-icon">ü§ñ</div>
        <div class="lib-title-section">
          <h2>Scikit-learn</h2>
          <div class="lib-tagline">Machine learning library with classical algorithms and utilities</div>
        </div>
      </div>

      <div class="lib-body">
        Scikit-learn is the standard library for classical machine learning. It provides implementations of virtually every standard algorithm: linear regression, logistic regression, decision trees, random forests, support vector machines, k-means clustering, and many more. These aren't the novel deep learning approaches that make headlines‚Äîthey're the workhorses of practical machine learning. Many real-world problems are solved with Scikit-learn, not neural networks.

        The elegance of Scikit-learn is its consistent interface. Every classifier or regressor has the same API: instantiate it, call fit on training data, call predict on test data. This consistency means once you understand one algorithm, you understand the interface for all. You can swap algorithms (replace RandomForestRegressor with GradientBoostingRegressor) with minimal code changes.

        Beyond algorithms, Scikit-learn provides essential ML utilities: train/test splitting, preprocessing (scaling, encoding), feature selection, and evaluation metrics. It's a complete toolkit for classical ML. When you're not using deep learning (and many times you shouldn't), Scikit-learn is your first choice.
      </div>

      <div class="teaching-box">
        <strong>Scikit-learn is the sensible default for machine learning.</strong> Before jumping to neural networks, try Scikit-learn. It's often sufficient, much faster to train, easier to interpret, and requires far less data. Deep learning is necessary when you have massive data and complex patterns. For everything else, Scikit-learn usually suffices.
      </div>

      <div class="code-block">
<span class="code-keyword">from</span> sklearn.<span class="code-function">model_selection</span> <span class="code-keyword">import</span> train_test_split
<span class="code-keyword">from</span> sklearn.<span class="code-function">preprocessing</span> <span class="code-keyword">import</span> StandardScaler
<span class="code-keyword">from</span> sklearn.<span class="code-function">ensemble</span> <span class="code-keyword">import</span> RandomForestClassifier
<span class="code-keyword">from</span> sklearn.<span class="code-function">metrics</span> <span class="code-keyword">import</span> accuracy_score, classification_report

<span class="code-comment"># Split data into train and test sets</span>
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=<span class="code-number">0.2</span>, random_state=<span class="code-number">42</span>
)

<span class="code-comment"># Preprocess: scale features to same range</span>
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

<span class="code-comment"># Train a model: same pattern for any algorithm</span>
model = RandomForestClassifier(n_estimators=<span class="code-number">100</span>)
model.fit(X_train_scaled, y_train)

<span class="code-comment"># Make predictions</span>
y_pred = model.predict(X_test_scaled)

<span class="code-comment"># Evaluate performance</span>
accuracy = accuracy_score(y_test, y_pred)
<span class="code-function">print</span>(<span class="code-string">f"Accuracy: {accuracy:.3f}"</span>)
<span class="code-function">print</span>(classification_report(y_test, y_pred))

<span class="code-comment"># Feature importance: understand what the model learned</span>
importances = model.feature_importances_
<span class="code-function">print</span>(<span class="code-string">"Top features:"</span>)
<span class="code-keyword">for</span> name, importance <span class="code-keyword">in</span> <span class="code-function">sorted</span>(<span class="code-function">zip</span>(feature_names, importances), reverse=<span class="code-keyword">True</span>)[:<span class="code-number">10</span>]:
    <span class="code-function">print</span>(<span class="code-string">f"  {name}: {importance:.3f}"</span>)
      </code-block>

      <div class="core-functions">
        <div class="functions-title">Core Scikit-learn Functions</div>
        <div class="function-list">
          <div class="function-item">
            <div class="function-name">train_test_split()</div>
            <div class="function-desc">Split data into train and test. Essential for honest evaluation.</div>
          </div>
          <div class="function-item">
            <div class="function-name">StandardScaler, MinMaxScaler</div>
            <div class="function-desc">Preprocessing to normalize features. Many algorithms expect same scale.</div>
          </div>
          <div class="function-item">
            <div class="function-name">RandomForestClassifier, GradientBoostingRegressor</div>
            <div class="function-desc">Ensemble models. Often provide best performance for tabular data.</div>
          </div>
          <div class="function-item">
            <div class="function-name">.fit(), .predict(), .score()</div>
            <div class="function-desc">Standard interface. Consistent across all algorithms.</div>
          </div>
          <div class="function-item">
            <div class="function-name">accuracy_score, precision_score, f1_score</div>
            <div class="function-desc">Evaluation metrics. Choose metric appropriate for your problem.</div>
          </div>
          <div class="function-item">
            <div class="function-name">SelectKBest, SelectFromModel</div>
            <div class="function-desc">Feature selection. Reduce features, improve interpretability.</div>
          </div>
          <div class="function-item">
            <div class="function-name">Pipeline</div>
            <div class="function-desc">Chain operations. Prevent data leakage, cleaner code.</div>
          </div>
          <div class="function-item">
            <div class="function-name">GridSearchCV, RandomizedSearchCV</div>
            <div class="function-desc">Hyperparameter tuning. Find best parameters automatically.</div>
          </div>
        </div>
      </div>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--hot);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">Baseline models and comparison benchmarks. When you don't know if deep learning is needed, try Scikit-learn first. Industry systems often use Scikit-learn‚Äîit's interpretable, fast to train, and reliable. Kaggle competitions use Scikit-learn extensively. It's the workhorse of practical machine learning.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--cool);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Not every problem needs deep learning. Scikit-learn solves most tabular data problems effectively. It trains quickly, requires less data, and produces interpretable models. Using the right tool for the job beats using the fanciest tool. Scikit-learn is often the right tool.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--green);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">For any tabular data problem before trying neural networks. For feature engineering and preprocessing. For baseline models to compare deep learning against. For interpretable models when stakeholders need to understand decisions. Understanding Scikit-learn is understanding practical machine learning.</div>
          </div>
        </div>
      </div>
    </div>

    <div class="library-card" style="--lib-color: var(--accent);">
      <div class="lib-header">
        <div class="lib-icon">üî¨</div>
        <div class="lib-title-section">
          <h2>SciPy & Requests</h2>
          <div class="lib-tagline">Scientific computing and HTTP communication</div>
        </div>
      </div>

      <div class="lib-body">
        SciPy extends NumPy with specialized scientific algorithms. It provides advanced linear algebra operations NumPy doesn't have, optimization algorithms beyond simple gradient descent, signal processing, statistics functions, and more. If NumPy is the foundation and Scikit-learn builds supervised learning on top, SciPy is the Swiss Army knife for specialized mathematical operations.

        Requests is smaller in scope but equally essential: it handles HTTP requests. When you need to fetch data from web APIs, use Requests. It abstracts away the complexity of HTTP communication, letting you focus on the data. In modern ML projects, data often comes from APIs‚ÄîTwitter data, stock data, weather data. Requests is how you fetch it.

        Together with NumPy, Pandas, Matplotlib, Seaborn, and Scikit-learn, these libraries form the complete toolkit for classical machine learning in Python.
      </div>

      <div class="code-block">
<span class="code-comment"># SciPy: optimization and advanced algorithms</span>
<span class="code-keyword">from</span> scipy.optimize <span class="code-keyword">import</span> minimize
<span class="code-keyword">from</span> scipy.stats <span class="code-keyword">import</span> norm, chi2

<span class="code-comment"># Find minimum of function</span>
<span class="code-keyword">def</span> <span class="code-function">objective</span>(x):
    <span class="code-keyword">return</span> (x - <span class="code-number">3</span>)**<span class="code-number">2</span> + (x - <span class="code-number">2</span>)**<span class="code-number">2</span>

result = minimize(objective, x0=<span class="code-number">0</span>)
<span class="code-function">print</span>(result.x)  <span class="code-comment"># Optimal x</span>

<span class="code-comment"># Requests: fetch data from web APIs</span>
<span class="code-keyword">import</span> requests
<span class="code-keyword">import</span> json

<span class="code-comment"># Fetch data from API</span>
response = requests.get(<span class="code-string">'https://api.example.com/data'</span>)
data = response.json()  <span class="code-comment"># Parse JSON response</span>

<span class="code-comment"># With authentication</span>
headers = {<span class="code-string">'Authorization'</span>: <span class="code-string">'Bearer TOKEN'</span>}
response = requests.get(url, headers=headers)

<span class="code-comment"># Post request to send data</span>
payload = {<span class="code-string">'name'</span>: <span class="code-string">'Alice'</span>, <span class="code-string">'age'</span>: <span class="code-number">25</span>}
response = requests.post(<span class="code-string">'https://api.example.com/users'</span>, json=payload)
      </code-block>

      <div class="impact-box">
        <div class="impact-grid">
          <div class="impact-item" style="--impact-color: var(--accent);">
            <div class="impact-item-title">üéØ Where It's Used</div>
            <div class="impact-item-content">SciPy for specialized scientific computing: optimization, advanced statistics, signal processing. Requests for any system that fetches data from web APIs. Modern ML projects integrate with external data sources‚ÄîRequests handles that communication.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--warm);">
            <div class="impact-item-title">üí° Why It Matters</div>
            <div class="impact-item-content">Real-world data comes from diverse sources. Requests abstracts HTTP complexity, letting you focus on data. SciPy provides algorithms beyond standard ML. Together with the rest of the ecosystem, they enable complete solutions.</div>
          </div>
          <div class="impact-item" style="--impact-color: var(--green);">
            <div class="impact-item-title">‚è±Ô∏è When You Need It</div>
            <div class="impact-item-content">SciPy when your problem requires specialized algorithms beyond standard ML. Requests when integrating with external data sources. In a typical project, Requests appears early (fetching data), Pandas in the middle (processing), Scikit-learn for modeling.</div>
          </div>
        </div>
      </div>
    </div>

  </section>

  <!-- ECOSYSTEM WORKFLOW -->
  <section>
    <div class="section-label">Putting It Together</div>
    <h2 class="section-title">A Complete ML Workflow Using These Libraries</h2>

    <div class="timeline">
      <div class="timeline-item">
        <div class="timeline-title">Data Acquisition (Requests)</div>
        <div class="timeline-desc">Fetch data from web APIs using Requests. Parse JSON responses. Store in files or databases. Often this is where projects start‚Äîyou need data to work with.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Data Loading and Exploration (Pandas)</div>
        <div class="timeline-desc">Load data using Pandas read_csv or other format readers. Inspect structure with info() and describe(). Understand your data before doing anything else. This phase often reveals data quality issues.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Visualization and Analysis (Matplotlib, Seaborn)</div>
        <div class="timeline-desc">Create plots to understand distributions, relationships, outliers. Visualization reveals patterns raw data doesn't show. This inspires feature engineering ideas and preprocessing decisions.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Data Cleaning and Preprocessing (Pandas, NumPy)</div>
        <div class="timeline-desc">Handle missing values, remove duplicates, fix inconsistencies. Transform and engineer features. Most project time happens here. Pandas and NumPy provide the tools.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Feature Engineering (NumPy, Pandas, Scikit-learn)</div>
        <div class="timeline-desc">Create new features that models can learn from. Scale features using Scikit-learn preprocessing. Select important features. Good features matter more than complex models.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Model Training (Scikit-learn)</div>
        <div class="timeline-desc">Split data into train/test. Train multiple models. Evaluate performance. Compare approaches. Scikit-learn provides both algorithms and utilities.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Model Evaluation and Visualization (Scikit-learn, Matplotlib)</div>
        <div class="timeline-desc">Compute evaluation metrics. Visualize predictions and errors. Understand failure modes. Use these insights to improve the model.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Hyperparameter Tuning (Scikit-learn)</div>
        <div class="timeline-desc">Use GridSearchCV or RandomizedSearchCV to find best hyperparameters. Improve model performance systematically. Often gives significant improvements.</div>
      </div>

      <div class="timeline-item">
        <div class="timeline-title">Deployment and Monitoring (Scikit-learn, Requests)</div>
        <div class="timeline-desc">Save trained models. Use Requests to fetch new data in production. Make predictions on new data. Monitor performance over time.</div>
      </div>
    </div>

  </section>

  <!-- COMPARISON TABLE -->
  <section>
    <div class="section-label">Quick Reference</div>
    <h2 class="section-title">When to Use Each Library</h2>

    <div class="comparison-section">
      <div class="table-header">
        <div class="table-label">Library</div>
        <div class="table-label">Best For</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>NumPy</strong></div>
        <div class="table-content">Numerical operations, linear algebra, arrays. Foundation for everything else. You'll use it indirectly through other libraries even if not directly.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>Pandas</strong></div>
        <div class="table-content">Loading, exploring, and cleaning tabular data. This is where you spend most time. Learn Pandas deeply‚Äîit's your daily tool in data work.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>Matplotlib</strong></div>
        <div class="table-content">Creating any type of plot. Flexible but verbose. Use it when you need complete control or want to create publication-quality figures.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>Seaborn</strong></div>
        <div class="table-content">Statistical visualizations with beautiful defaults. Great for exploratory analysis. Use it first for quick visualizations; switch to Matplotlib when you need tweaks.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>Scikit-learn</strong></div>
        <div class="table-content">Classical machine learning algorithms and utilities. Start here before trying deep learning. Produces interpretable models quickly.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>SciPy</strong></div>
        <div class="table-content">Specialized scientific algorithms. Optimization, advanced statistics, signal processing. Use when NumPy doesn't have what you need.</div>
      </div>
      <div class="table-row">
        <div class="table-content"><strong>Requests</strong></div>
        <div class="table-content">Fetching data from web APIs. Parsing JSON responses. Any time you need to communicate with web services.</div>
      </div>
    </div>

  </section>

</div>

<!-- Footer -->
<footer>
  <p class="footer-text">Essential Python Libraries ‚Äî Building Complete ML Solutions</p>
</footer>

</body>
</html>
